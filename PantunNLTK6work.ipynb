{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3099a309f6a44aeac0a7b300f04be51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec6bd2ad465a49f480b6ccd9e1aaaccc",
              "IPY_MODEL_32db7c2bbff3486782e6f4dc775154be",
              "IPY_MODEL_e97c494d1934473ea564d62b01bb9565"
            ],
            "layout": "IPY_MODEL_accc3e7202794213a5a635f13251fb75"
          }
        },
        "ec6bd2ad465a49f480b6ccd9e1aaaccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5efda6d1fa8e4bea8d4350633b5b3575",
            "placeholder": "​",
            "style": "IPY_MODEL_df4cf57a30e542d98df6eead2d08a16d",
            "value": "Batches: 100%"
          }
        },
        "32db7c2bbff3486782e6f4dc775154be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197ceddfefca4d56bbdc3a254c0bbad6",
            "max": 44,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_563b9cc6e2654987bbf4aa8c69d601f9",
            "value": 44
          }
        },
        "e97c494d1934473ea564d62b01bb9565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b429424b99473696df7f20b59c2f74",
            "placeholder": "​",
            "style": "IPY_MODEL_0aa772968b0045b4b7f5562b99b6efa0",
            "value": " 44/44 [01:35&lt;00:00,  1.82s/it]"
          }
        },
        "accc3e7202794213a5a635f13251fb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5efda6d1fa8e4bea8d4350633b5b3575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4cf57a30e542d98df6eead2d08a16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "197ceddfefca4d56bbdc3a254c0bbad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563b9cc6e2654987bbf4aa8c69d601f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34b429424b99473696df7f20b59c2f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa772968b0045b4b7f5562b99b6efa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OthmanHaikal/pantun-generator/blob/master/PantunNLTK6work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "utf8_file = \"Pantun_v3_utf8.txt\"\n",
        "if os.path.exists(utf8_file):\n",
        "    os.remove(utf8_file)\n",
        "\n",
        "import glob\n",
        "\n",
        "# Define the pattern for redundant files\n",
        "pattern = \"Pantun_v4.txt\"\n",
        "\n",
        "# Delete all files matching the pattern\n",
        "for file in glob.glob(pattern):\n",
        "    os.remove(file)\n",
        "    print(f\"Deleted: {file}\")\n",
        "\n",
        "# Keep the corrected file\n",
        "print(\"Cleanup complete. Ensure you are working with Pantun_v3_utf8.txt.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObXf5AUiW1Uo",
        "outputId": "3209f959-b3b6-4e83-d62a-c39150dbec0a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleanup complete. Ensure you are working with Pantun_v3_utf8.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Choose your Pantun_v3.txt (or similar file)\n",
        "\n",
        "!pip install chardet\n",
        "import chardet\n",
        "\n",
        "file_path = \"Pantun_v4.txt\"\n",
        "\n",
        "# Read the raw bytes\n",
        "with open(file_path, \"rb\") as f:\n",
        "    raw_data = f.read()\n",
        "\n",
        "# Detect the encoding\n",
        "result = chardet.detect(raw_data)\n",
        "detected_encoding = result[\"encoding\"]\n",
        "confidence = result[\"confidence\"]\n",
        "print(\"Detected encoding:\", detected_encoding)\n",
        "print(\"Confidence:\", confidence)\n",
        "\n",
        "# Decode and re-encode as UTF-8\n",
        "text_decoded = raw_data.decode(detected_encoding, errors=\"replace\")\n",
        "\n",
        "new_file_path = \"Pantun_v4_utf8.txt\"\n",
        "with open(new_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text_decoded)\n",
        "\n",
        "print(\"File converted to UTF-8 and saved as:\", new_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "WlR5Y6sRMjCb",
        "outputId": "9ef37063-2ef5-4c69-dcaf-320b00797c6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4bceefa8-6bf1-48df-851a-49d853a43cb8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4bceefa8-6bf1-48df-851a-49d853a43cb8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Pantun_v4.txt to Pantun_v4.txt\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Detected encoding: Windows-1254\n",
            "Confidence: 0.7449215323230243\n",
            "File converted to UTF-8 and saved as: Pantun_v4_utf8.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pantun(file_path):\n",
        "    \"\"\"\n",
        "    Reads the text file (UTF-8) where each pantun is 4 lines,\n",
        "    separated by a blank line.\n",
        "    Returns a list of lists: each sub-list = [line1, line2, line3, line4].\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [line.strip() for line in f]\n",
        "\n",
        "    pantuns = []\n",
        "    pantun_buffer = []\n",
        "\n",
        "    for line in lines:\n",
        "        if not line:  # blank line => pantun boundary\n",
        "            if len(pantun_buffer) == 4:\n",
        "                pantuns.append(pantun_buffer)\n",
        "            pantun_buffer = []\n",
        "        else:\n",
        "            pantun_buffer.append(line)\n",
        "\n",
        "    # Handle the last pantun if the file doesn't end with a blank line\n",
        "    if len(pantun_buffer) == 4:\n",
        "        pantuns.append(pantun_buffer)\n",
        "\n",
        "    return pantuns\n",
        "\n",
        "# Now load from the converted UTF-8 file\n",
        "utf8_file = \"Pantun_v4_utf8.txt\"\n",
        "pantun_list = load_pantun(utf8_file)\n",
        "\n",
        "print(\"Number of pantun loaded:\", len(pantun_list))\n",
        "for i, pantun in enumerate(pantun_list[:3], start=1):  # Show first 3 pantun\n",
        "    print(f\"\\nPantun #{i}:\")\n",
        "    for line in pantun:\n",
        "        print(line)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_pantun = pd.DataFrame(pantun_list, columns=[\"line1\", \"line2\", \"line3\", \"line4\"])\n",
        "df_pantun[\"id\"] = range(1, len(df_pantun) + 1)\n",
        "\n",
        "print(df_pantun.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NPLl1oBKTZ5",
        "outputId": "8ad2b8ba-d731-48c9-c539-95522ada5ed6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pantun loaded: 1390\n",
            "\n",
            "Pantun #1:\n",
            "Pakai cincin di jari manis,\n",
            "Bawa saksi mangga dua,\n",
            "Abang pimpin jangan nangis,\n",
            "Sudah jodoh kita berdua.\n",
            "\n",
            "Pantun #2:\n",
            "Kain batik kepala dua,\n",
            "Pakai mari sebelah kiri,\n",
            "Sudah suka kita berdua,\n",
            "Orang lain jangan peduli.\n",
            "\n",
            "Pantun #3:\n",
            "Sayang gulatik burung guladan,\n",
            "Sayang tekukur terbang tinggi,\n",
            "Sudah cantik sama padan,\n",
            "Mari ukur siapa yang tinggi.\n",
            "                            line1                           line2  \\\n",
            "0     Pakai cincin di jari manis,          Bawa saksi mangga dua,   \n",
            "1          Kain batik kepala dua,        Pakai mari sebelah kiri,   \n",
            "2  Sayang gulatik burung guladan,  Sayang tekukur terbang tinggi,   \n",
            "3  Sayang tekukur gulainya lemak,  Sayang selasih di bawa batang,   \n",
            "4      Ada satu si burung helang,     Pandai menyambar ikan duri,   \n",
            "\n",
            "                           line3                            line4  id  \n",
            "0    Abang pimpin jangan nangis,         Sudah jodoh kita berdua.   1  \n",
            "1        Sudah suka kita berdua,        Orang lain jangan peduli.   2  \n",
            "2       Sudah cantik sama padan,     Mari ukur siapa yang tinggi.   3  \n",
            "3   Sudah lumpur berjalan semak,  Kerana cik adik saya mendatang.   4  \n",
            "4  Hidup dunia tak campur orang,           Mana tahu adat negeri.   5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pantun(file_path):\n",
        "    \"\"\"\n",
        "    Reads the text file (UTF-8) where each pantun is 4 lines,\n",
        "    separated by a blank line.\n",
        "    Returns a list of lists: each sub-list = [line1, line2, line3, line4].\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [line.strip() for line in f]  # Strip leading/trailing whitespace\n",
        "\n",
        "    pantuns = []\n",
        "    pantun_buffer = []\n",
        "\n",
        "    for line in lines:\n",
        "        if not line:  # Blank line => pantun boundary\n",
        "            if len(pantun_buffer) == 4:\n",
        "                pantuns.append(pantun_buffer)  # Add complete pantun\n",
        "            pantun_buffer = []  # Reset buffer\n",
        "        else:\n",
        "            pantun_buffer.append(line)\n",
        "\n",
        "    # Handle the last pantun if the file doesn't end with a blank line\n",
        "    if len(pantun_buffer) == 4:\n",
        "        pantuns.append(pantun_buffer)\n",
        "\n",
        "    return pantuns\n",
        "\n",
        "# Preprocess and save to CSV\n",
        "utf8_file = \"Pantun_v4_utf8.txt\"\n",
        "pantun_list = load_pantun(utf8_file)\n",
        "\n",
        "df_pantun = pd.DataFrame(pantun_list, columns=[\"line1\", \"line2\", \"line3\", \"line4\"])\n",
        "df_pantun[\"id\"] = range(1, len(df_pantun) + 1)\n",
        "\n",
        "# Save to CSV\n",
        "df_pantun.to_csv(\"pantun_cleaned.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Display the first few rows to verify correctness\n",
        "print(\"\\nDataFrame preview:\")\n",
        "print(df_pantun.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GANWm2NIP2Iz",
        "outputId": "00323113-791f-4467-9064-893f816f8169"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame preview:\n",
            "                            line1                           line2  \\\n",
            "0     Pakai cincin di jari manis,          Bawa saksi mangga dua,   \n",
            "1          Kain batik kepala dua,        Pakai mari sebelah kiri,   \n",
            "2  Sayang gulatik burung guladan,  Sayang tekukur terbang tinggi,   \n",
            "3  Sayang tekukur gulainya lemak,  Sayang selasih di bawa batang,   \n",
            "4      Ada satu si burung helang,     Pandai menyambar ikan duri,   \n",
            "\n",
            "                           line3                            line4  id  \n",
            "0    Abang pimpin jangan nangis,         Sudah jodoh kita berdua.   1  \n",
            "1        Sudah suka kita berdua,        Orang lain jangan peduli.   2  \n",
            "2       Sudah cantik sama padan,     Mari ukur siapa yang tinggi.   3  \n",
            "3   Sudah lumpur berjalan semak,  Kerana cik adik saya mendatang.   4  \n",
            "4  Hidup dunia tak campur orang,           Mana tahu adat negeri.   5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers faiss-cpu pandas\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# =========================\n",
        "# STEP 1: LOAD YOUR PANTUN DATA\n",
        "# =========================\n",
        "# Load the cleaned CSV file\n",
        "CSV_PATH = \"pantun_cleaned.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Combine pantun lines\n",
        "def combine_pantun_lines(row):\n",
        "    return (\n",
        "        row[\"line1\"] + \" \" +\n",
        "        row[\"line2\"] + \" \" +\n",
        "        row[\"line3\"] + \" \" +\n",
        "        row[\"line4\"]\n",
        "    )\n",
        "\n",
        "df[\"pantun_text\"] = df.apply(combine_pantun_lines, axis=1)\n",
        "\n",
        "# Display for verification\n",
        "print(\"Combined pantun text preview:\")\n",
        "print(df[[\"id\", \"pantun_text\"]].head())\n",
        "\n",
        "# =========================\n",
        "# STEP 2: EMBEDDING MODEL\n",
        "# =========================\n",
        "# For multilingual (including Malay), you can use:\n",
        "#   'distiluse-base-multilingual-cased-v2'\n",
        "# or you could try other multilingual models from SentenceTransformers\n",
        "model_name = \"distiluse-base-multilingual-cased-v2\"\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "# =========================\n",
        "# STEP 3: EMBED THE PANTUN TEXTS\n",
        "# =========================\n",
        "pantun_texts = df[\"pantun_text\"].tolist()\n",
        "embeddings = model.encode(pantun_texts, show_progress_bar=True)\n",
        "\n",
        "# Convert to float32 (Faiss requires float32 arrays)\n",
        "embeddings = np.array(embeddings, dtype=\"float32\")\n",
        "\n",
        "# =========================\n",
        "# STEP 4: BUILD A FAISS INDEX\n",
        "# =========================\n",
        "# We'll build a simple Faiss index (L2 / Euclidean)\n",
        "d = embeddings.shape[1]  # dimension of embeddings\n",
        "index = faiss.IndexFlatL2(d)  # or use other indexing structures for large data\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"Total pantun embeddings indexed: {index.ntotal}\")\n",
        "\n",
        "# =========================\n",
        "# STEP 5: SEARCH FUNCTION\n",
        "# =========================\n",
        "def semantic_search(query, top_k=3):\n",
        "    \"\"\"\n",
        "    Given a query (string), returns the top_k most similar pantun from the index.\n",
        "    \"\"\"\n",
        "    # 1. Encode query\n",
        "    query_embedding = model.encode([query], show_progress_bar=False)\n",
        "    query_embedding = np.array(query_embedding, dtype=\"float32\")\n",
        "\n",
        "    # 2. Search in Faiss\n",
        "    distances, indices = index.search(query_embedding, top_k)\n",
        "\n",
        "    # 'indices' is shape [1, top_k] => a list of pantun indices\n",
        "    # 'distances' is shape [1, top_k] => a list of distances (lower = more similar)\n",
        "    results = []\n",
        "    for dist, idx in zip(distances[0], indices[0]):\n",
        "        pantun_row = df.iloc[idx]\n",
        "        results.append({\n",
        "            \"id\": pantun_row[\"id\"],\n",
        "            \"lines\": [\n",
        "                pantun_row[\"line1\"],\n",
        "                pantun_row[\"line2\"],\n",
        "                pantun_row[\"line3\"],\n",
        "                pantun_row[\"line4\"]\n",
        "            ],\n",
        "            \"distance\": dist  # you can use this to gauge similarity\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# =========================\n",
        "# STEP 6: INTERACTIVE LOOP (EXAMPLE)\n",
        "# =========================\n",
        "def print_pantun(pantun_item):\n",
        "    \"\"\"Helper to neatly print a pantun item from our search result.\"\"\"\n",
        "    lines = pantun_item[\"lines\"]\n",
        "    print(\"—\" * 40)\n",
        "    for ln in lines:\n",
        "        print(ln)\n",
        "    print(f\"(ID: {pantun_item['id']}, Distance: {pantun_item['distance']:.4f})\")\n",
        "\n",
        "def main():\n",
        "    print(\"Selamat datang ke sistem pantun (Semantic Search)!\")\n",
        "    print(\"Taip 'exit' untuk keluar.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_query = input(\"Anda: \")\n",
        "        if user_query.lower() in [\"exit\", \"keluar\", \"quit\"]:\n",
        "            print(\"Terima kasih. Jumpa lagi!\")\n",
        "            break\n",
        "\n",
        "        # 1. Perform semantic search\n",
        "        results = semantic_search(user_query, top_k=5)\n",
        "\n",
        "        # 2. Show top 1 pantun by default\n",
        "        best_pantun = results[0]\n",
        "        print(\"\\nIni cadangan pantun yang paling hampir dengan soalan/kata kunci anda:\")\n",
        "        print_pantun(best_pantun)\n",
        "\n",
        "        # 3. Ask user if they want more\n",
        "        while True:\n",
        "            more = input(\"Mahukan pantun lain? (y/n): \").strip().lower()\n",
        "            if more == \"y\":\n",
        "                # If they want another pantun, show the next best from the list\n",
        "                # For simplicity, let's pop from results:\n",
        "                if len(results) > 1:\n",
        "                    results.pop(0)  # remove the first one\n",
        "                    next_best = results[0]\n",
        "                    print_pantun(next_best)\n",
        "                else:\n",
        "                    print(\"Maaf, tiada lagi cadangan pantun.\")\n",
        "                    break\n",
        "            else:\n",
        "                break\n",
        "        print()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c3099a309f6a44aeac0a7b300f04be51",
            "ec6bd2ad465a49f480b6ccd9e1aaaccc",
            "32db7c2bbff3486782e6f4dc775154be",
            "e97c494d1934473ea564d62b01bb9565",
            "accc3e7202794213a5a635f13251fb75",
            "5efda6d1fa8e4bea8d4350633b5b3575",
            "df4cf57a30e542d98df6eead2d08a16d",
            "197ceddfefca4d56bbdc3a254c0bbad6",
            "563b9cc6e2654987bbf4aa8c69d601f9",
            "34b429424b99473696df7f20b59c2f74",
            "0aa772968b0045b4b7f5562b99b6efa0"
          ]
        },
        "id": "kxzt4NBbKW_0",
        "outputId": "d7553089-c62d-4a33-bbc1-9ed51ba1327f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n",
            "Combined pantun text preview:\n",
            "   id                                        pantun_text\n",
            "0   1  Pakai cincin di jari manis, Bawa saksi mangga ...\n",
            "1   2  Kain batik kepala dua, Pakai mari sebelah kiri...\n",
            "2   3  Sayang gulatik burung guladan, Sayang tekukur ...\n",
            "3   4  Sayang tekukur gulainya lemak, Sayang selasih ...\n",
            "4   5  Ada satu si burung helang, Pandai menyambar ik...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3099a309f6a44aeac0a7b300f04be51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pantun embeddings indexed: 1390\n",
            "Selamat datang ke sistem pantun (Semantic Search)!\n",
            "Taip 'exit' untuk keluar.\n",
            "\n",
            "Anda: buatkan pantun tentang kasih pada anak\n",
            "\n",
            "Ini cadangan pantun yang paling hampir dengan soalan/kata kunci anda:\n",
            "————————————————————————————————————————\n",
            "Suka menumpang di kayu buruk,\n",
            "Ada seekor anaknya beruk,\n",
            "Zahir ketara batin tersorok,\n",
            "Kasih sayang di mana nak taruk.\n",
            "(ID: 126, Distance: 0.5267)\n",
            "Mahukan pantun lain? (y/n): n\n",
            "\n",
            "Anda: buatkan pantun tentang kasih sayang\n",
            "\n",
            "Ini cadangan pantun yang paling hampir dengan soalan/kata kunci anda:\n",
            "————————————————————————————————————————\n",
            "Layang - layang putus teraju,\n",
            "Jatuh tersangkut di pokok delima,\n",
            "Kasih sayang sudah setuju,\n",
            "Tentu boleh berkekal lama.\n",
            "(ID: 95, Distance: 0.4989)\n",
            "Mahukan pantun lain? (y/n): n\n",
            "\n",
            "Anda: exit\n",
            "Terima kasih. Jumpa lagi!\n"
          ]
        }
      ]
    }
  ]
}